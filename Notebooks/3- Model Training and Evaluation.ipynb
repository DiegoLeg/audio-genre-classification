{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessed data from the previous notebook is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r x_train \n",
    "%store -r x_test \n",
    "%store -r y_train \n",
    "%store -r y_test \n",
    "%store -r yy \n",
    "%store -r label_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first place, a K-Nearest Neighbor algorithm is tested. In order to find k, GridSearch is used with a series of parameters to evaluate. Using GridSearch we can evaluate all the possible combinations of the hyperparameters values using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining grid parameters for the algorithm to test\n",
    "\n",
    "grid_params = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 15],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_neighbors': [3, 5, 7, 9, 11, 15], 'metric': ['euclidean', 'manhattan'], 'weights': ['uniform', 'distance']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn = GridSearchCV(KNeighborsClassifier(), grid_params, scoring='accuracy',cv=5)\n",
    "model_knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the accuracy of our model and also the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  0  2  1  0  1  1  0  0  0]\n",
      " [ 1 12  0  0  0  2  0  0  0  1]\n",
      " [ 0  0 14  2  2  1  1  0  2  3]\n",
      " [ 0  0  2  9  2  1  0  2  3  2]\n",
      " [ 1  0  1  3  3  0  2  1  4  1]\n",
      " [ 1  1  3  0  0 13  0  1  2  0]\n",
      " [ 1  0  1  1  2  1 20  0  0  1]\n",
      " [ 0  0  1  1  0  0  0  6  1  1]\n",
      " [ 0  0  2  2  6  1  0  2  8  5]\n",
      " [ 1  0  1  2  0  2  1  1  3  7]]\n"
     ]
    }
   ],
   "source": [
    "y_predict_knn = model_knn.predict(x_test)\n",
    "\n",
    "#Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_predict_knn, y_test)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'distance'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best parameters found by GridSearch\n",
    "model_knn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score on validation set (accuracy) = 0.5525\n",
      "Best score on test set (accuracy) = 0.5350\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score on validation set (accuracy) = {:.4f}\".format(model_knn.best_score_))\n",
    "print(\"Best score on test set (accuracy) = {:.4f}\".format(accuracy_score(y_test, y_predict_knn)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed that the first model have an accuracy of 0.53 for the test set. This is quite far from promising, so we will try to improve. Let's try with another models before changing some parameters in the preprocessing notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a simple Decision Tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=10,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'splitter': ['best', 'random'], 'criterion': ['gini', 'entropy']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define parameters for a Grid Search\n",
    "\n",
    "grid_params_tree = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"splitter\": [\"best\", \"random\"],\n",
    "}\n",
    "\n",
    "# Train a decision tree model\n",
    "\n",
    "model_tree = GridSearchCV(DecisionTreeClassifier(random_state=10),grid_params_tree, scoring='accuracy', cv=5)\n",
    "model_tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to predict the labels for our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  1  6  1  0  1  1  0  0  4]\n",
      " [ 0 11  3  0  0  0  0  0  0  0]\n",
      " [ 0  0  8  0  1  4  0  0  4  0]\n",
      " [ 1  0  2  5  2  1  1  2  2  3]\n",
      " [ 0  0  1  3  2  1  2  0  6  3]\n",
      " [ 3  1  2  0  0 10  0  0  2  3]\n",
      " [ 2  0  1  2  2  0 18  0  2  1]\n",
      " [ 0  0  0  1  2  0  0  8  1  0]\n",
      " [ 0  0  0  3  5  2  1  1  5  1]\n",
      " [ 3  0  4  6  1  3  2  2  1  6]]\n"
     ]
    }
   ],
   "source": [
    "y_predict_tree = model_tree.predict(x_test)\n",
    "\n",
    "#class_rep_tree = classification_report(y_test, predict_labels_tree)\n",
    "conf_matrix_tree = confusion_matrix(y_predict_tree, y_test)\n",
    "print(conf_matrix_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score on validation set (accuracy) = 0.4325\n",
      "Best score on test set (accuracy) = 0.4200\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score on validation set (accuracy) = {:.4f}\".format(model_tree.best_score_))\n",
    "print(\"Best score on test set (accuracy) = {:.4f}\".format(accuracy_score(y_test, y_predict_tree)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that Accuracy has not improved in this case. We have a value of 0.42 for the test set. Let's try some additional models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what can we do with a Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [100, 250, 500, 1000], 'criterion': ['gini', 'entropy'], 'max_depth': [5, 7, None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine some parameters for a Grid Search\n",
    "\n",
    "grid_params_forest = {\n",
    "    \"n_estimators\": [100, 250, 500, 1000],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [5, 7, None]\n",
    "}\n",
    "\n",
    "# Defining the model\n",
    "\n",
    "model_forest = GridSearchCV(RandomForestClassifier(),grid_params_forest, scoring='accuracy', cv=5)\n",
    "\n",
    "model_forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14  0  0  0  0  2  2  0  0  2]\n",
      " [ 0 13  0  0  0  0  0  0  0  0]\n",
      " [ 6  1  9  2  0  4  1  2  1  1]\n",
      " [ 1  0  0 12  1  0  0  2  1  4]\n",
      " [ 0  0  0  1  6  0  1  2  4  1]\n",
      " [ 4  0  2  1  0 13  1  0  1  0]\n",
      " [ 1  0  0  1  1  0 21  0  0  1]\n",
      " [ 0  0  1  1  0  1  0  8  2  0]\n",
      " [ 0  1  2  2  2  1  2  2  9  2]\n",
      " [ 2  1  2  3  1  0  1  2  1  8]]\n"
     ]
    }
   ],
   "source": [
    "y_predict_forest = model_forest.predict(x_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_predict_forest)\n",
    "print(conf_matrix)\n",
    "#print(classification_report(y_test, y_predict_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score on validation set (accuracy) = 0.5787\n",
      "Best score on test set (accuracy) = 0.5650\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score on validation set (accuracy) = {:.4f}\".format(model_forest.best_score_))\n",
    "print(\"Best score on test set (accuracy) = {:.4f}\".format(accuracy_score(y_test, y_predict_forest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieved a better accuracy using this model than the Decision Tree model. Random Forest is a more robust algorithm, so it's expected having better metrics than the previous model. Let's try another one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will compare the performance of our models to a Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=10, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.5, 1, 2, 5], 'max_iter': [500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_params_log = {\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"C\": [0.5, 1, 2, 5],\n",
    "    \"max_iter\": [500]\n",
    "}\n",
    "\n",
    "model_logreg = GridSearchCV(LogisticRegression(random_state=10),grid_params_log, scoring='accuracy', cv=5)\n",
    "model_logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  0  0  0  1  2  2  0  0  3]\n",
      " [ 0 13  0  0  0  0  0  0  0  0]\n",
      " [10  0  8  1  1  1  0  3  1  2]\n",
      " [ 2  0  0  8  4  0  0  2  3  2]\n",
      " [ 2  0  1  1  4  0  1  2  4  0]\n",
      " [ 4  1  3  2  0  7  0  0  5  0]\n",
      " [ 1  0  0  1  0  0 22  0  0  1]\n",
      " [ 0  0  1  1  0  0  0  9  2  0]\n",
      " [ 4  0  2  4  1  1  0  1  9  1]\n",
      " [ 7  0  1  2  1  2  1  2  1  4]]\n"
     ]
    }
   ],
   "source": [
    "y_predict_logreg = model_logreg.predict(x_test)\n",
    "#print(classification_report(y_test, y_predict_logreg))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_predict_logreg)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score on validation set (accuracy) = 0.5663\n",
      "Best score on test set (accuracy) = 0.4800\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score on validation set (accuracy) = {:.4f}\".format(model_logreg.best_score_))\n",
    "print(\"Best score on test set (accuracy) = {:.4f}\".format(accuracy_score(y_test, y_predict_logreg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the previous models, we have an accuracy of 0.48 for the test set. We can try to make some modifications to the preprocessing (more number of mel coefficients for example, as we are using only 12 and the default is 20) to see if we can achieve better metrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
