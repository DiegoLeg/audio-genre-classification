{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessed data from the previous notebook is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r x_train \n",
    "%store -r x_test \n",
    "%store -r y_train \n",
    "%store -r y_test \n",
    "%store -r yy \n",
    "%store -r label_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first place, a K-Nearest Neighbor algorithm is tested. In order to find k, GridSearch is used with a series of parameters to evaluate. Using GridSearch we can evaluate all the possible combinations of the hyperparameters values using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining grid parameters for the algorithm to test\n",
    "\n",
    "grid_params = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 15],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_neighbors': [3, 5, 7, 9, 11, 15], 'metric': ['euclidean', 'manhattan'], 'weights': ['uniform', 'distance']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn = GridSearchCV(KNeighborsClassifier(), grid_params, scoring='accuracy',cv=5)\n",
    "model_knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the accuracy of our model and also the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  0  0  0  0  2  0  0  0  1]\n",
      " [ 0 12  1  0  0  0  0  0  0  0]\n",
      " [ 0  0 20  2  3  2  0  1  1  3]\n",
      " [ 0  0  3 12  0  1  0  0  1  1]\n",
      " [ 0  0  1  2  8  0  2  3  7  1]\n",
      " [ 2  1  1  0  0 12  0  0  1  1]\n",
      " [ 1  0  0  0  0  1 21  0  0  0]\n",
      " [ 0  0  1  2  3  0  0  9  2  1]\n",
      " [ 0  0  0  2  1  1  0  0  9  2]\n",
      " [ 2  0  0  1  0  3  2  0  2 11]]\n"
     ]
    }
   ],
   "source": [
    "y_predict_knn = model_knn.predict(x_test)\n",
    "\n",
    "#Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_predict_knn, y_test)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'distance'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best parameters found by GridSearch\n",
    "model_knn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score on validation set (accuracy) = 0.5813\n",
      "Best score on test set (accuracy) = 0.6450\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score on validation set (accuracy) = {:.4f}\".format(model_knn.best_score_))\n",
    "print(\"Best score on test set (accuracy) = {:.4f}\".format(accuracy_score(y_test, y_predict_knn)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an improved accuracy of 0.64 here, in relation to the previous models. This is a good step on our model, and it's also the highest value achieved. Let's see the performance of the remaining models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a simple Decision Tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=10,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'splitter': ['best', 'random'], 'criterion': ['gini', 'entropy']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define parameters for a Grid Search\n",
    "\n",
    "grid_params_tree = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"splitter\": [\"best\", \"random\"],\n",
    "}\n",
    "\n",
    "# Train a decision tree model\n",
    "\n",
    "model_tree = GridSearchCV(DecisionTreeClassifier(random_state=10),grid_params_tree, scoring='accuracy', cv=5)\n",
    "model_tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to predict the labels for our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  1  2  1  0  1  0  0  1  3]\n",
      " [ 0 10  1  0  1  2  0  1  1  0]\n",
      " [ 3  0 10  1  2  0  0  0  0  1]\n",
      " [ 1  0  1  6  3  2  2  1  2  2]\n",
      " [ 0  1  1  3  5  0  0  1  5  2]\n",
      " [ 2  1  7  0  0 13  0  0  2  1]\n",
      " [ 3  0  1  1  0  1 21  0  0  0]\n",
      " [ 0  0  1  1  0  1  0  8  2  2]\n",
      " [ 0  0  2  2  2  2  0  1  7  3]\n",
      " [ 0  0  1  6  2  0  2  1  3  7]]\n"
     ]
    }
   ],
   "source": [
    "y_predict_tree = model_tree.predict(x_test)\n",
    "\n",
    "#class_rep_tree = classification_report(y_test, predict_labels_tree)\n",
    "conf_matrix_tree = confusion_matrix(y_predict_tree, y_test)\n",
    "print(conf_matrix_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score on validation set (accuracy) = 0.4425\n",
      "Best score on test set (accuracy) = 0.4900\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score on validation set (accuracy) = {:.4f}\".format(model_tree.best_score_))\n",
    "print(\"Best score on test set (accuracy) = {:.4f}\".format(accuracy_score(y_test, y_predict_tree)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the MinMaxScaler have null impact on the Decision Tree classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what can we do with a Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [100, 250, 500, 1000], 'criterion': ['gini', 'entropy'], 'max_depth': [5, 7, None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine some parameters for a Grid Search\n",
    "\n",
    "grid_params_forest = {\n",
    "    \"n_estimators\": [100, 250, 500, 1000],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [5, 7, None]\n",
    "}\n",
    "\n",
    "# Defining the model\n",
    "\n",
    "model_forest = GridSearchCV(RandomForestClassifier(),grid_params_forest, scoring='accuracy', cv=5)\n",
    "\n",
    "model_forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  1  0  1  0  2  4  0  0  2]\n",
      " [ 0 13  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 16  1  1  3  1  2  1  2]\n",
      " [ 0  0  0 12  3  0  0  3  2  1]\n",
      " [ 0  0  0  2  4  0  1  3  4  1]\n",
      " [ 1  0  1  0  0 15  1  0  2  2]\n",
      " [ 0  0  0  0  2  0 21  0  0  2]\n",
      " [ 0  0  1  1  0  0  0  8  2  1]\n",
      " [ 1  1  2  2  5  1  1  2  7  1]\n",
      " [ 2  0  3  4  1  0  0  1  2  8]]\n"
     ]
    }
   ],
   "source": [
    "y_predict_forest = model_forest.predict(x_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_predict_forest)\n",
    "print(conf_matrix)\n",
    "#print(classification_report(y_test, y_predict_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score on validation set (accuracy) = 0.6125\n",
      "Best score on test set (accuracy) = 0.5700\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score on validation set (accuracy) = {:.4f}\".format(model_forest.best_score_))\n",
    "print(\"Best score on test set (accuracy) = {:.4f}\".format(accuracy_score(y_test, y_predict_forest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the accuracy of the model on the test set does not improve. The major improvement was seen on the previous version (v1.1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will compare the performance of our models to a Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=10, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.5, 1, 2, 5], 'max_iter': [500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_params_log = {\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"C\": [0.5, 1, 2, 5],\n",
    "    \"max_iter\": [500]\n",
    "}\n",
    "\n",
    "model_logreg = GridSearchCV(LogisticRegression(random_state=10),grid_params_log, scoring='accuracy', cv=5)\n",
    "model_logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  0  1  0  0  1  6  0  0  4]\n",
      " [ 0 13  0  0  0  0  0  0  0  0]\n",
      " [ 9  0 11  1  1  2  0  1  0  2]\n",
      " [ 3  0  0 10  2  0  0  1  4  1]\n",
      " [ 0  0  2  1  4  1  1  2  3  1]\n",
      " [ 2  2  2  1  1 14  0  0  0  0]\n",
      " [ 1  0  0  0  1  0 22  0  0  1]\n",
      " [ 0  0  0  1  1  0  0 10  0  1]\n",
      " [ 2  0  2  2  4  1  1  1  8  2]\n",
      " [ 5  0  2  4  2  1  1  2  1  3]]\n"
     ]
    }
   ],
   "source": [
    "y_predict_logreg = model_logreg.predict(x_test)\n",
    "#print(classification_report(y_test, y_predict_logreg))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_predict_logreg)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score on validation set (accuracy) = 0.5887\n",
      "Best score on test set (accuracy) = 0.5150\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score on validation set (accuracy) = {:.4f}\".format(model_logreg.best_score_))\n",
    "print(\"Best score on test set (accuracy) = {:.4f}\".format(accuracy_score(y_test, y_predict_logreg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we don't see an improvement in relation to the previous version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, using 20 Mel-Coefficients have a impact on the accuracy scored by some of the models. MinMaxScaler have an influence on some of the models. This scaling is intended for a Neural Network input, so let's try to analyse some models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
