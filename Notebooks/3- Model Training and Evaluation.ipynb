{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessed data from the previous notebook is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%store -r x_train \n",
    "%store -r x_test \n",
    "%store -r y_train \n",
    "%store -r y_test \n",
    "%store -r yy \n",
    "%store -r label_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first place, a K-Nearest Neighbor algorithm is tested. In order to find k, GridSearch is used with a series of parameters to evaluate. Using GridSearch we can evaluate all the possible combinations of the hyperparameters values using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining grid parameters for the algorithm to test\n",
    "\n",
    "grid_params = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 15],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_neighbors': [3, 5, 7, 9, 11, 15], 'metric': ['euclidean', 'manhattan'], 'weights': ['uniform', 'distance']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn = GridSearchCV(KNeighborsClassifier(), grid_params, scoring='accuracy',cv=5)\n",
    "model_knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the accuracy of our model and also the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  0  0  0  0  1  0  0  0  0]\n",
      " [ 0 12  1  0  0  1  0  0  0  0]\n",
      " [ 3  0 17  2  3  4  0  1  1  5]\n",
      " [ 0  0  2 10  0  1  0  0  1  2]\n",
      " [ 0  1  1  2  8  0  2  3  6  2]\n",
      " [ 1  0  2  0  0 11  0  0  2  1]\n",
      " [ 2  0  0  1  0  1 21  0  0  0]\n",
      " [ 0  0  1  2  3  0  0  9  2  1]\n",
      " [ 0  0  1  1  1  0  0  0  9  2]\n",
      " [ 2  0  2  3  0  3  2  0  2  8]]\n"
     ]
    }
   ],
   "source": [
    "y_predict_knn = model_knn.predict(x_test)\n",
    "\n",
    "#Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_predict_knn, y_test)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'distance'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best parameters found by GridSearch\n",
    "model_knn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score on validation set (accuracy) = 0.5775\n",
      "Best score on test set (accuracy) = 0.5850\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score on validation set (accuracy) = {:.4f}\".format(model_knn.best_score_))\n",
    "print(\"Best score on test set (accuracy) = {:.4f}\".format(accuracy_score(y_test, y_predict_knn)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We improved our accuracy here! We have 0.53 on the previous notebook (v1.0) so this is a little step further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a simple Decision Tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=10,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'splitter': ['best', 'random'], 'criterion': ['gini', 'entropy']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define parameters for a Grid Search\n",
    "\n",
    "grid_params_tree = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"splitter\": [\"best\", \"random\"],\n",
    "}\n",
    "\n",
    "# Train a decision tree model\n",
    "\n",
    "model_tree = GridSearchCV(DecisionTreeClassifier(random_state=10),grid_params_tree, scoring='accuracy', cv=5)\n",
    "model_tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to predict the labels for our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  1  2  1  0  1  0  0  1  3]\n",
      " [ 0 10  1  0  1  2  0  1  1  0]\n",
      " [ 3  0 10  1  2  0  0  0  0  1]\n",
      " [ 1  0  1  6  3  2  2  1  2  2]\n",
      " [ 0  1  1  3  5  0  0  1  5  2]\n",
      " [ 2  1  7  0  0 13  0  0  2  1]\n",
      " [ 3  0  1  1  0  1 21  0  0  0]\n",
      " [ 0  0  1  1  0  1  0  8  2  2]\n",
      " [ 0  0  2  2  2  2  0  1  7  3]\n",
      " [ 0  0  1  6  2  0  2  1  3  7]]\n"
     ]
    }
   ],
   "source": [
    "y_predict_tree = model_tree.predict(x_test)\n",
    "\n",
    "#class_rep_tree = classification_report(y_test, predict_labels_tree)\n",
    "conf_matrix_tree = confusion_matrix(y_predict_tree, y_test)\n",
    "print(conf_matrix_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score on validation set (accuracy) = 0.4425\n",
      "Best score on test set (accuracy) = 0.4900\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score on validation set (accuracy) = {:.4f}\".format(model_tree.best_score_))\n",
    "print(\"Best score on test set (accuracy) = {:.4f}\".format(accuracy_score(y_test, y_predict_tree)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we have an improvement too, from 0.42 on the test set to 0.49. Seems that more Mel Coefficients improve our models. Let's see the performance of the remaining models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what can we do with a Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [100, 250, 500, 1000], 'criterion': ['gini', 'entropy'], 'max_depth': [5, 7, None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine some parameters for a Grid Search\n",
    "\n",
    "grid_params_forest = {\n",
    "    \"n_estimators\": [100, 250, 500, 1000],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [5, 7, None]\n",
    "}\n",
    "\n",
    "# Defining the model\n",
    "\n",
    "model_forest = GridSearchCV(RandomForestClassifier(),grid_params_forest, scoring='accuracy', cv=5)\n",
    "\n",
    "model_forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0  0  0  2  3  0  0  2]\n",
      " [ 0 13  0  0  0  0  0  0  0  0]\n",
      " [ 1  0 15  1  1  3  1  2  1  2]\n",
      " [ 0  0  1 13  2  0  0  1  3  1]\n",
      " [ 0  0  0  1  7  0  2  2  2  1]\n",
      " [ 0  2  0  0  0 14  1  0  3  2]\n",
      " [ 0  0  0  0  2  0 22  0  0  1]\n",
      " [ 0  0  2  1  0  0  0  7  2  1]\n",
      " [ 1  0  2  2  3  2  1  2  9  1]\n",
      " [ 3  0  2  3  1  1  0  1  1  9]]\n"
     ]
    }
   ],
   "source": [
    "y_predict_forest = model_forest.predict(x_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_predict_forest)\n",
    "print(conf_matrix)\n",
    "#print(classification_report(y_test, y_predict_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score on validation set (accuracy) = 0.6125\n",
      "Best score on test set (accuracy) = 0.6100\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score on validation set (accuracy) = {:.4f}\".format(model_forest.best_score_))\n",
    "print(\"Best score on test set (accuracy) = {:.4f}\".format(accuracy_score(y_test, y_predict_forest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we have the same trend. More Mel Coefficients translates into a improved accuracy of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will compare the performance of our models to a Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/diego/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=10, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.5, 1, 2, 5], 'max_iter': [500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_params_log = {\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"C\": [0.5, 1, 2, 5],\n",
    "    \"max_iter\": [500]\n",
    "}\n",
    "\n",
    "model_logreg = GridSearchCV(LogisticRegression(random_state=10),grid_params_log, scoring='accuracy', cv=5)\n",
    "model_logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  0  1  0  1  1  4  0  0  4]\n",
      " [ 0 13  0  0  0  0  0  0  0  0]\n",
      " [ 9  0 12  1  1  2  0  1  0  1]\n",
      " [ 3  0  0 10  2  0  0  0  4  2]\n",
      " [ 0  0  2  0  5  1  0  0  6  1]\n",
      " [ 2  2  2  1  1 14  0  0  0  0]\n",
      " [ 1  0  1  0  1  0 22  0  0  0]\n",
      " [ 0  0  0  1  0  0  0 11  0  1]\n",
      " [ 2  0  2  1  4  1  1  1  9  2]\n",
      " [ 4  0  2  3  2  2  1  2  1  4]]\n"
     ]
    }
   ],
   "source": [
    "y_predict_logreg = model_logreg.predict(x_test)\n",
    "#print(classification_report(y_test, y_predict_logreg))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_predict_logreg)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score on validation set (accuracy) = 0.5938\n",
      "Best score on test set (accuracy) = 0.5450\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score on validation set (accuracy) = {:.4f}\".format(model_logreg.best_score_))\n",
    "print(\"Best score on test set (accuracy) = {:.4f}\".format(accuracy_score(y_test, y_predict_logreg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we also have an improvement in relation to the previous version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, using 20 Mel-Coefficients have a major impact on the accuracy scored by some of the models: every model performed better in this version. Futhermore, we will try with another scaler (MinMax scaler instead of Standard), and a Neural Network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
